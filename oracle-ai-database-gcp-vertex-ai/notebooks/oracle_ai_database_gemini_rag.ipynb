{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed1decb0",
   "metadata": {},
   "source": [
    "## Oracle Database RAG with Gemini & Vertex AI\n",
    "\n",
    "Run the RAG application code snippets in this Jupyter notebook.\n",
    "\n",
    "Execute each code cell in sequence from top to bottom. To run a code cell, select it and click Run. When a cell completes, a number will appear in the square brackets. You can then proceed to the next cell.\n",
    "\n",
    "**Prerequisites:**\n",
    "- Python virtual environment activated with all required packages\n",
    "- GCP authentication completed (`gcloud auth application-default login`)\n",
    "- `.env` file configured with database credentials\n",
    "\n",
    "**Libraries used:**\n",
    "- LangChain for RAG orchestration\n",
    "- Oracle AI Vector Search (OracleVS) for vector storage\n",
    "- Vertex AI for embeddings and LLM (Gemini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb247737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and modules\n",
    "\n",
    "import time\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# Suppress tqdm warning about ipywidgets\n",
    "warnings.filterwarnings('ignore', message='IProgress not found')\n",
    "\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "from langchain_google_vertexai import (\n",
    "    ChatVertexAI,\n",
    "    VertexAIEmbeddings,\n",
    "    VertexAI,\n",
    ")\n",
    "\n",
    "print('‚úì Successfully imported libraries and modules')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45024fb2",
   "metadata": {},
   "source": [
    "## Step 1: Define metadata wrapper function\n",
    "\n",
    "This function formats and adds metadata to chunks for the Oracle Vector Store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d06c796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to format and add metadata to Oracle 26ai Vector Store\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "def chunks_to_docs_wrapper(row: dict) -> Document:\n",
    "    \"\"\"\n",
    "    Converts text into a Document object suitable for ingestion into Oracle Vector Store.\n",
    "    \"\"\"\n",
    "    metadata = {'id': row['id'], 'link': row['link']}\n",
    "    return Document(page_content=row['text'], metadata=metadata)\n",
    "\n",
    "print(\"Successfully defined metadata wrapper\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3233600d",
   "metadata": {},
   "source": [
    "## Step 2: Connect to Oracle Database 26ai\n",
    "\n",
    "Update with your credentials:\n",
    "- **Username**\n",
    "- **Password** \n",
    "- **Connection String** (from tnsnames.ora)\n",
    "- **Wallet Password**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec5ed69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import oracledb\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file (in parent directory)\n",
    "env_path = os.path.join(os.path.dirname(os.getcwd()), '.env')\n",
    "# Use override=True to ensure .env values take precedence over existing env vars\n",
    "load_dotenv(dotenv_path=env_path, override=True)\n",
    "\n",
    "# Get database credentials from environment variables\n",
    "un = os.getenv(\"DB_USERNAME\")\n",
    "pw = os.getenv(\"DB_PASSWORD\")\n",
    "dsn = os.getenv(\"DB_DSN\")\n",
    "wallet_path = os.getenv(\"DB_WALLET_DIR\")\n",
    "wpwd = os.getenv(\"DB_WALLET_PASSWORD\", \"\")\n",
    "\n",
    "# Debug: Show what we loaded (mask password)\n",
    "print(f\"Loaded from .env:\")\n",
    "print(f\"  DB_USERNAME: {un}\")\n",
    "print(f\"  DB_DSN: {dsn}\")\n",
    "print(f\"  DB_WALLET_DIR: {wallet_path}\")\n",
    "print(f\"  DB_WALLET_PASSWORD: {'*' * len(wpwd) if wpwd else '(empty)'}\")\n",
    "print()\n",
    "\n",
    "connection = oracledb.connect(\n",
    "    config_dir=wallet_path,\n",
    "    user=un, \n",
    "    password=pw, \n",
    "    dsn=dsn,\n",
    "    wallet_location=wallet_path,\n",
    "    wallet_password=wpwd\n",
    ")\n",
    "\n",
    "print(\"Successfully connected to Oracle Database 26ai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4057596",
   "metadata": {},
   "source": [
    "## Step 3: Load PDF Document\n",
    "\n",
    "Load the PDF document and display basic information about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4903d8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from io import BytesIO\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "# Download PDF from Oracle documentation\n",
    "pdf_url = 'https://docs.oracle.com/en/database/oracle/oracle-database/26/nfcoa/oracle-ai-database-26ai-new-features-guide.pdf'\n",
    "print(f\"Downloading PDF from: {pdf_url}\")\n",
    "\n",
    "response = requests.get(pdf_url)\n",
    "response.raise_for_status()  # Raise error if download fails\n",
    "\n",
    "# Load PDF from downloaded bytes\n",
    "pdf = PdfReader(BytesIO(response.content))\n",
    "print(f\"‚úì Successfully downloaded PDF\")\n",
    "print(f\"The number of pages in this document is {len(pdf.pages)}\")\n",
    "print(\"\\n--- First Page Preview ---\")\n",
    "print(pdf.pages[0].extract_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0b501d",
   "metadata": {},
   "source": [
    "## Step 4: Transform PDF to Text\n",
    "\n",
    "Extract text from all pages of the PDF document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a171a57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if pdf is not None:\n",
    "    print(\"Transforming the PDF document to text...\")\n",
    "    text = \"\"\n",
    "    for page in pdf.pages:\n",
    "        text += page.extract_text()\n",
    "    print(f\"Successfully transformed {len(pdf.pages)} pages to text\")\n",
    "    print(f\"Total text length: {len(text)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf747a85",
   "metadata": {},
   "source": [
    "## Step 5: Split Text into Chunks\n",
    "\n",
    "Chunk size: 800 characters with 100 character overlap.\n",
    "\n",
    "**Note:** Chunk sizes vary depending on document type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed8fb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=800,\n",
    "    chunk_overlap=100,\n",
    "    length_function=len\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_text(text)\n",
    "print(f\"Created {len(chunks)} chunks\")\n",
    "print(\"\\n--- First Chunk Preview ---\")\n",
    "print(chunks[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa421cb9",
   "metadata": {},
   "source": [
    "## Step 6: Create Documents with Metadata\n",
    "\n",
    "Wrap each chunk with metadata (id and link) for storage in the vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740749ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "    chunks_to_docs_wrapper({\n",
    "        'id': f'{page_num}', \n",
    "        'link': f'Page {page_num}', \n",
    "        'text': text\n",
    "    }) \n",
    "    for page_num, text in enumerate(chunks)\n",
    "]\n",
    "\n",
    "print(f\"Created {len(docs)} documents with metadata\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d775079",
   "metadata": {},
   "source": [
    "## Step 7: Initialize Vertex AI\n",
    "\n",
    "Configure your Google Cloud project and region for Vertex AI services."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a2e46d",
   "metadata": {},
   "source": [
    "## Step 6a: Authenticate with GCP (First Time Setup)\n",
    "\n",
    "**Run this ONCE on your GCP VM to set up authentication:**\n",
    "\n",
    "```bash\n",
    "# In the VM terminal (not in notebook):\n",
    "gcloud auth application-default login --no-launch-browser\n",
    "```\n",
    "\n",
    "Follow the URL, copy the authorization code, and paste it back.\n",
    "\n",
    "**OR** if you have a service account key file:\n",
    "```bash\n",
    "export GOOGLE_APPLICATION_CREDENTIALS=\"/path/to/your/service-account-key.json\"\n",
    "```\n",
    "\n",
    "‚ö†Ô∏è **After authentication, restart the kernel and re-run from the top.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f31338c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import vertexai\n",
    "\n",
    "PROJECT_ID = \"adb-pm-prod\"  # Update with your GCP Project ID\n",
    "REGION = \"us-central1\"             # Update with your region (us-central1 has most models)\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=REGION)\n",
    "print(f\"Initialized Vertex AI for project: {PROJECT_ID} in region: {REGION}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4a91aa",
   "metadata": {},
   "source": [
    "## Step 8: Embed and Store Vectors in Oracle 26ai\n",
    "\n",
    "Using **VertexAIEmbeddings** model and **DOT_PRODUCT** distance strategy for similarity search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1087fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores.oraclevs import OracleVS\n",
    "from langchain_community.vectorstores.utils import DistanceStrategy\n",
    "\n",
    "embeddings = VertexAIEmbeddings(model_name=\"text-embedding-004\")\n",
    "\n",
    "s1time = time.time()\n",
    "print(f\"Vectorizing and inserting {len(docs)} chunks into Oracle Database 26ai...\")\n",
    "print(\"Processing in smaller batches to avoid token limits...\")\n",
    "\n",
    "# Process in batches of 50 (to stay under 20k token limit)\n",
    "batch_size = 50\n",
    "knowledge_base = None\n",
    "\n",
    "for i in range(0, len(docs), batch_size):\n",
    "    batch = docs[i:i + batch_size]\n",
    "    batch_num = (i // batch_size) + 1\n",
    "    total_batches = (len(docs) + batch_size - 1) // batch_size\n",
    "    print(f\"  Processing batch {batch_num}/{total_batches} ({len(batch)} chunks)...\")\n",
    "    \n",
    "    if knowledge_base is None:\n",
    "        # Create the vector store with first batch\n",
    "        knowledge_base = OracleVS.from_documents(\n",
    "            batch,\n",
    "            embeddings,\n",
    "            client=connection,\n",
    "            table_name=\"RAG_TAB\",\n",
    "            distance_strategy=DistanceStrategy.DOT_PRODUCT\n",
    "        )\n",
    "    else:\n",
    "        # Add remaining batches to existing store\n",
    "        knowledge_base.add_documents(batch)\n",
    "\n",
    "s2time = time.time()\n",
    "print(f\"‚úì Vectorizing and inserting chunks duration: {round(s2time - s1time, 1)} sec.\")\n",
    "print(f\"‚úì Successfully stored {len(docs)} chunks in Oracle Database 26ai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665addad",
   "metadata": {},
   "source": [
    "## Step 9: Verify Data in Oracle Database\n",
    "\n",
    "Query the RAG_TAB table to confirm vectors were inserted successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353be3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = \"RAG_TAB\"\n",
    "\n",
    "with connection.cursor() as cursor:\n",
    "    query = f\"SELECT * FROM {table_name}\"\n",
    "    cursor.execute(query)\n",
    "    rows = cursor.fetchall()\n",
    "    \n",
    "    print(f\"Total rows in {table_name}: {len(rows)}\")\n",
    "    print(\"\\n--- Sample Rows (first 3) ---\")\n",
    "    for row in rows[:3]:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb76fc5a",
   "metadata": {},
   "source": [
    "## Step 10: Define User Question\n",
    "\n",
    "Ask a question about the document content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6ed180",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_question = 'Tell me more about JSON Relational Duality'\n",
    "print(f\"The prompt to the LLM will be: {user_question}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0fc0fa",
   "metadata": {},
   "source": [
    "## Step 11: Perform Similarity Search\n",
    "\n",
    "Test the vector similarity search to find relevant chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e2a4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if user_question:\n",
    "    s3time = time.time()\n",
    "    result_chunks = knowledge_base.similarity_search(user_question, k=5)\n",
    "    s4time = time.time()\n",
    "    \n",
    "    print(f\"‚úì Search duration: {round(s4time - s3time, 1)} sec.\")\n",
    "    print(f\"\\nFound {len(result_chunks)} relevant chunks:\")\n",
    "    for i, chunk in enumerate(result_chunks, 1):\n",
    "        print(f\"\\nChunk {i}: {chunk.page_content[:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b346a9d",
   "metadata": {},
   "source": [
    "## Step 12: Configure Gemini LLM\n",
    "\n",
    "Set up Vertex AI's **Gemini 2.0 Flash** model for generating responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b69f6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatVertexAI(\n",
    "    model_name=\"gemini-2.5-flash\",\n",
    "    max_output_tokens=8192,\n",
    "    temperature=0.7,\n",
    "    top_p=0.95,\n",
    "    top_k=40,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"‚úì Configured Gemini 2.5 Flash model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9332d6",
   "metadata": {},
   "source": [
    "## Step 13: Build RAG Prompt Template\n",
    "\n",
    "Create the prompt template and retriever for the RAG pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cd31c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Answer the question based only on the following context:\n",
    "            {context} Question: {question} \"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "retriever = knowledge_base.as_retriever(search_kwargs={\"k\": 10})\n",
    "print(\"The template is:\", template)\n",
    "print(retriever)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a87a2b",
   "metadata": {},
   "source": [
    "## Step 14: Execute RAG Chain\n",
    "\n",
    "Invoke the complete RAG pipeline to generate the final response.\n",
    "\n",
    "The chain:\n",
    "1. Retrieves relevant context from Oracle Vector DB\n",
    "2. Constructs prompt with question + context\n",
    "3. Sends to Gemini LLM for response generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1e35d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "s5time = time.time()\n",
    "print(\"Sending prompt and RAG context to Gemini LLM...\")\n",
    "print(f\"Question: {user_question}\\n\")\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "response = chain.invoke(user_question)\n",
    "\n",
    "s6time = time.time()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"RESPONSE:\")\n",
    "print(\"=\" * 80)\n",
    "print(response)\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\n‚úì LLM response duration: {round(s6time - s5time, 1)} sec.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f58e1c",
   "metadata": {},
   "source": [
    "## üéâ Congratulations!\n",
    "\n",
    "You've successfully built a complete RAG application with:\n",
    "- **Oracle Database 26ai** for vector storage\n",
    "- **Vertex AI Embeddings** for vectorization  \n",
    "- **Gemini 2.5 Flash** for response generation\n",
    "- **LangChain 1.x** for orchestration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc11e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"üéâ RAG Application Complete!\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\n‚úì PDF loaded and processed\")\n",
    "print(\"‚úì Text chunked and vectorized\") \n",
    "print(\"‚úì Vectors stored in Oracle Database 26ai\")\n",
    "print(\"‚úì Similarity search working\")\n",
    "print(\"‚úì Gemini LLM integration successful\")\n",
    "print(\"\\nYou've completed the RAG application lab!\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
